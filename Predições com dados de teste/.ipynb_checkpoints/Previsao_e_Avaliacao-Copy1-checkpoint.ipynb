{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194ff010-ecd9-4b13-8eea-6ce5fa037595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import os, json, joblib\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import URL\n",
    "from pathlib import Path\n",
    "import unicodedata as ud\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deafb03-7938-4609-a710-a3a8e934b88a",
   "metadata": {},
   "source": [
    "### Conectando com o Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398e39a1-83d7-4b16-a8f0-86d86d632ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HOST = os.getenv(\"PGHOST\")\n",
    "PORT = os.getenv(\"PGPORT\")\n",
    "DB   = os.getenv(\"PGDATABASE\")\n",
    "USR  = os.getenv(\"PGUSER\")\n",
    "PWD  = os.getenv(\"PGPASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a15f0a2f-3741-4b16-afe4-a903bb872f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo .env existe? True \n",
      "Caminho: C:\\Users\\cicer\\Documents\\Case Técnico Paipe\\Análise Exploratória\\.env\n",
      "{'PGHOST': 'localhost', 'PGPORT': '5432', 'PGDATABASE': 'PaipeTech', 'PGUSER': 'postgres'} | PGPASSWORD set? True\n"
     ]
    }
   ],
   "source": [
    "# 1) Caminho .env local\n",
    "ENV_PATH = Path(r\"C:\\Users\\cicer\\Documents\\Case Técnico Paipe\\Análise Exploratória\\.env\")\n",
    "print(\"Arquivo .env existe?\", ENV_PATH.exists(), \"\\nCaminho:\", ENV_PATH)\n",
    "\n",
    "# 2) Carrega o .env\n",
    "load_dotenv(dotenv_path=ENV_PATH, override=True)\n",
    "\n",
    "# 3) Confere o que foi lido\n",
    "cfg = {k: os.getenv(k) for k in [\"PGHOST\", \"PGPORT\", \"PGDATABASE\", \"PGUSER\"]}\n",
    "print(cfg, \"| PGPASSWORD set?\", bool(os.getenv(\"PGPASSWORD\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98260448-8636-4ced-b661-f8c865977e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB atual: PaipeTech\n",
      "Versão: PostgreSQL 18.0 on x86_64-windows, compiled by msvc-19.44.35215, 64-bit\n"
     ]
    }
   ],
   "source": [
    "HOST = os.getenv(\"PGHOST\", \"localhost\")\n",
    "PORT = int(os.getenv(\"PGPORT\") or 5432)\n",
    "DB   = os.getenv(\"PGDATABASE\")\n",
    "USR  = os.getenv(\"PGUSER\")\n",
    "PWD  = os.getenv(\"PGPASSWORD\")\n",
    "\n",
    "url = URL.create(\n",
    "    \"postgresql+psycopg2\",\n",
    "    username=USR,\n",
    "    password=PWD,   \n",
    "    host=HOST,\n",
    "    port=PORT,\n",
    "    database=DB,\n",
    ")\n",
    "\n",
    "engine = create_engine(url, pool_pre_ping=True)\n",
    "\n",
    "# teste rápido\n",
    "with engine.begin() as conn:\n",
    "    print(\"DB atual:\", conn.execute(text(\"SELECT current_database()\")).scalar())\n",
    "    print(\"Versão:\",  conn.execute(text(\"SELECT version()\")).scalar().splitlines()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ae6225-0fcf-4769-946c-dc2e00ec15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(text(\"SELECT * FROM public.teste\"), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d65862b7-73e1-44c1-ac8d-33e5aa907bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      previsoes\n",
      "0  2.312421e+07\n",
      "1  2.002220e+07\n",
      "2  3.974290e+07\n",
      "3  1.899952e+07\n",
      "4  3.890357e+07\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "df_test = df \n",
    "\n",
    "# Padroniza nomes\n",
    "df_test_raw = df_test.copy()\n",
    "df_test_raw.columns = [c.lower() for c in df_test_raw.columns]\n",
    "\n",
    "try:\n",
    "    BASE = '.' \n",
    "    base_candidates = [Path(BASE)]\n",
    "except NameError:\n",
    "    base_candidates = [Path(\".\"), Path(\"./models_lgbm_corrigido\"), Path(\"./models_lgbm\")]\n",
    "\n",
    "meta_path = model_path = None\n",
    "for d in base_candidates:\n",
    "    if (d / \"inference_meta.json\").exists() and meta_path is None:\n",
    "        meta_path = d / \"inference_meta.json\"\n",
    "    if (d / \"lgbm_model_final.pkl\").exists() and model_path is None:\n",
    "        model_path = d / \"lgbm_model_final.pkl\"\n",
    "\n",
    "if meta_path is None or model_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Não encontrei 'inference_meta.json' ou 'lgbm_model_final.pkl' em {base_candidates}. \"\n",
    "        \"Ajuste os caminhos conforme onde você salvou os artefatos.\"\n",
    "    )\n",
    "\n",
    "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "X_COLS     = meta[\"X_cols\"]\n",
    "CAT_LEVELS = meta[\"categorical_levels\"]\n",
    "\n",
    "#  Pré-processamento \n",
    "def build_features_infer(df: pd.DataFrame, X_COLS, CAT_LEVELS) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # tempo médio até estação\n",
    "    base_time = pd.to_numeric(df.get(\"timetoneareststation\"), errors=\"coerce\")\n",
    "    min_t = pd.to_numeric(df.get(\"mintimetoneareststation\"), errors=\"coerce\")\n",
    "    max_t = pd.to_numeric(df.get(\"maxtimetoneareststation\"), errors=\"coerce\")\n",
    "    time_mean = base_time.copy() if isinstance(base_time, pd.Series) else pd.Series(np.nan, index=df.index)\n",
    "    mask_nan = time_mean.isna()\n",
    "    time_mean.loc[mask_nan] = (min_t[mask_nan] + max_t[mask_nan]) / 2.0\n",
    "    df[\"time_to_station_mean\"] = time_mean\n",
    "\n",
    "    # logs \n",
    "    for src, dst in [\n",
    "        (\"totalfloorarea\", \"log_totalfloorarea\"),\n",
    "        (\"area\",           \"log_area\"),\n",
    "        (\"frontage\",       \"log_frontage\"),\n",
    "        (\"breadth\",        \"log_breadth\"),\n",
    "    ]:\n",
    "        if src in df.columns:\n",
    "            df[dst] = np.log1p(pd.to_numeric(df[src], errors=\"coerce\").fillna(0))\n",
    "\n",
    "    # numéricos básicos\n",
    "    for c in [\"buildingyear\",\"coverageratio\",\"floorarearatio\",\"year\",\"quarter\",\"municipalitycode\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # normalizar renovation\n",
    "    if \"renovation\" in df.columns:\n",
    "        df[\"renovation\"] = (\n",
    "            df[\"renovation\"].astype(str).str.strip()\n",
    "              .replace({\"Yes\":\"Done\",\"No\":\"Not yet\",\"nan\":\"Not yet\",\"NaN\":\"Not yet\"})\n",
    "        )\n",
    "\n",
    "    # aplicar níveis categóricos fixos\n",
    "    for c, levels in CAT_LEVELS.items():\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.Categorical(df[c].astype(str), categories=levels)\n",
    "\n",
    "    for c in X_COLS:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "test_f = build_features_infer(df_test_raw, X_COLS, CAT_LEVELS)\n",
    "\n",
    "X_te = test_f[X_COLS].copy()\n",
    "for c in X_te.columns:\n",
    "    if str(X_te[c].dtype) in [\"object\", \"string\"]:\n",
    "        X_te[c] = X_te[c].astype(\"category\")\n",
    "\n",
    "#  Carregar o modelo salvo e prever \n",
    "model = joblib.load(str(model_path))\n",
    "\n",
    "pred_log = model.predict(X_te)\n",
    "pred = np.maximum(np.expm1(pred_log), 0)  # volta à escala original\n",
    "\n",
    "#  Adiciona coluna 'previsoes' no DF original \n",
    "df_test_out = df_test_raw.copy()\n",
    "df_test_out[\"previsoes\"] = pred\n",
    "\n",
    "# visualizar/salvar\n",
    "print(df_test_out[[\"previsoes\"]].head())\n",
    "# df_test_out.to_csv(\"test_with_predictions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
